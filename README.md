# üìê Arquitectura del proyecto

> **Objetivo**: montar, poblar y exponer un _pipeline_ de an√°lisis de sentimiento casi en tiempo real usando servicios en Docker sobre una VM de Azure, orquestado por GitHub Actions. El resultado se visualiza en **Metabase** a partir de datos consolidados en **MySQL**.

---

## 1) Visi√≥n general (alto nivel)

```
[Productor (Kafka)]  ‚Üí  [Consumer ‚Üí MongoDB]  ‚Üí  [Worker DL (clasifica)]  ‚Üí  [MySQL (DW)]  ‚Üí  [Metabase]
                                      ‚îÇ                                  
                                    (Kafka UI / Mongo Express / Jupyter para pruebas)
```

- **Kafka** recibe mensajes (comentarios/texto).
- **consumer_to_mongo.py** persiste esos mensajes crudos en **MongoDB**.
- **sentiment_dl_worker.py** aplica un modelo (DL/ML) y genera **sentiment_label** / **sentiment_score**.
- Los resultados se **materializan en MySQL** (tabla de hechos tipo *Dw Messages*).
- **Metabase** lee MySQL para KPIs y dashboards.

Servicios de apoyo: **Kafka UI**, **Mongo Express**, **Redis/RedisInsight** (opcional), **Jupyter** para pruebas y notebooks.

---

## 2) Infraestructura y despliegue

### 2.1 Azure + Terraform
- Carpeta **`terraform/`**: crea **Resource Group**, **VNet/NSG**, y una **VM Linux**.
- **`cloud-init.yml`**: arranque inicial (instala Docker, usuarios, etc.).
- Workflow **`.github/workflows/00-terraform.yml`**: CI/CD para `init/plan/apply` (ejecuci√≥n manual protegida).

### 2.2 VM + Docker
- Todos los contenedores viven en la red Docker **`labnet`** para descubrirse por nombre: `mysql`, `mongodb`, `kafka`, `metabase`, etc.
- Puertos expuestos (por defecto):
  - **Metabase** `3000`, **MySQL** `3306`, **MongoDB** `27017`, **Kafka UI** `9000`, **Mongo Express** `8081`, **RedisInsight** `8001`, **Jupyter** `8888`.
- Vol√∫menes relevantes:
  - **Metabase**: `-v metabase-data:/metabase-data` (`MB_DB_FILE=/metabase-data/metabase.db`).

---

## 3) Plano de datos (contenedores y roles)

| Servicio | Contenedor | Rol principal |
|---|---|---|
| Kafka | `kafka` | _Broker_ + listeners interno/externo, recibe mensajes de texto |
| Kafka UI | `kafka-ui` | Observabilidad y pruebas de topics |
| MongoDB | `mongodb` | Almac√©n crudo / *staging* (colecci√≥n de mensajes) |
| Mongo Express | `mongo-express` | Admin web Mongo |
| MySQL | `mysql` | *Data Warehouse* ligero (tabla **Dw Messages**) |
| Metabase | `metabase` | Visualizaci√≥n/BI (dashboards/KPIs) |
| Redis / RedisInsight | `redis`, `redisinsight` | Cache/labs (opcional) |
| HBase (opcional) | `hbase` | Experimentos (no cr√≠tico al flujo E2E) |
| Jupyter | (en VM) | Notebooks de exploraci√≥n y utilidades |

**Red interna**: todos unidos a `labnet`, por lo que los *hosts* se refieren por **nombre de contenedor** (p.ej., `mysql:3306`, `mongodb:27017`, `kafka:9092`).

---

## 4) Flujo de datos E2E

1. **Ingesta**
   - **`send_kafka_burst.py`** y/o **`export_sentiment140.py`** publican mensajes (texto) en un _topic_ de Kafka.
2. **Stage en Mongo**
   - **`consumer_to_mongo.py`** consume el topic y escribe documentos en **MongoDB** (colecci√≥n cruda con `comment`, `user_id`, `created_at`, etc.).
3. **Inferencia de sentimiento**
   - **`sentiment_dl_worker.py`** lee desde **Mongo**, infiere `sentiment_label` (`pos/neg/neu/vpos...`) y `sentiment_score` (0‚Äì1).
4. **Consolidaci√≥n en MySQL**
   - El worker inserta/actualiza la tabla **`Dw Messages`** en **MySQL** (hechos listos para BI).
5. **BI y dashboard**
   - **Metabase** se conecta a `mysql:3306` (usuario app) y muestra:
     - Total de mensajes.
     - Conteo por sentimiento.
     - Serie temporal por d√≠a.

> **Nota**: tambi√©n se puede usar el notebook **`notebook/01-Proyecto-sentiment_dl_pipeline_mongo_to_mysql.ipynb`** para pruebas, EDA y *sanity checks*.

---

## 5) Automatizaci√≥n (GitHub Actions)

Carpeta **`.github/workflows/`** (ejecuci√≥n remota contra la VM):

- **`00-terraform.yml`** ‚Äì Provisiona/actualiza la infraestructura en Azure.
- **`01-ensure-prereqs.yml`** ‚Äì Verifica prerequisitos (Docker, permisos, paquetes base).
- **`02-restart-lab-services.yml`** ‚Äì Crea/red (`labnet`), arranca/ reinicia contenedores base.
- **`03-start-extras.yml`** ‚Äì Servicios opcionales (Redis, HBase, etc.).
- **`04-init-data-plane.yml`** ‚Äì Inicializa topics/colecciones/tablas y datos de ejemplo.
- **`05-install-ml-deps.yml`** ‚Äì Instala dependencias de ML/DL (PyTorch, tokenizers, etc.).
- **`06-setup-metabase.yml`** ‚Äì *Seed* local: healthcheck, *setup/login*, registrar MySQL, crear tarjetas y dashboard.
- **`07-Manage_Lab_VM.yml`** ‚Äì Utilidades de mantenimiento (apagar/encender, logs, etc.).
- **`step10-start-services.yml`** ‚Äì Arranque de servicios principales para demo.
- **`step11-setup-metabase-public.yml`** ‚Äì Variante para exponer Metabase via IP p√∫blica (seguros/NSG).
- **`step12-bringup-demo-e2e.yml`** ‚Äì Orquestaci√≥n de punta a punta (ingesta‚ÜíBI).
- **`step13-sanity-checks.yml`** ‚Äì Chequeos b√°sicos (salud de APIs, conteos, etc.).

Cada workflow usa **`az vm run-command`** para ejecutar scripts dentro de la VM (sin abrir SSH manualmente), o Terraform para IaC.

---

## 6) Scripts clave (carpeta `scripts/`)

- **`init_data_plane.sh`**: prepara red Docker `labnet`, levanta contenedores base (Kafka, Mongo, etc.), variables y puertos.
- **`restart_lab_services.sh`**: reinicio seguro de contenedores.
- **`install_ml_deps.sh`**: instala dependencias de ML usadas por el worker.
- **`setup_metabase_and_seed.sh`**: idempotente. _Setup_ / login Metabase, registra MySQL y crea 3 tarjetas + dashboard.
- **`consumer_to_mongo.py`**: consumidor Kafka ‚Üí Mongo.
- **`send_kafka_burst.py`**: productor de mensajes a Kafka.
- **`export_sentiment140.py`**: carga dataset de ejemplo al topic.
- **`sentiment_dl_worker.py`**: clasifica sentimiento y escribe a MySQL.

---

## 7) Modelo de datos (DW ligero en MySQL)

Tabla **`Dw Messages`** (nombres ilustrativos):
- `id` (hash/uuid del mensaje)
- `user_id`
- `comment`
- `ingest_ts` (fecha/hora de ingesta)
- `sentiment_label` (e.g., `pos/neg/neu/vpos`)
- `sentiment_score` (float 0‚Äì1)
- `raw_json` (opcional)

> **Prop√≥sito**: tabla de hechos simple optimizada para consultas en Metabase.

---

## 8) Seguridad y credenciales (demo)

- **MySQL**: usuario app `metabase` con permisos **read‚Äëonly** sobre `lab.*` (creado por SQL de bootstrap) y `root:pass` para administraci√≥n local.
- **Metabase**: persistido en volumen `metabase-data`. Config original se hace v√≠a API local (`127.0.0.1:3000`) desde la VM.
- **NSG**: abrir solo los puertos necesarios (idealmente restringidos por IP). Para exposici√≥n p√∫blica de Metabase, usar el workflow de *public setup*.
- **Jupyter**: sin token por defecto en modo laboratorio ‚Üí proteger v√≠a NSG / t√∫nel SSH.

> En producci√≥n, mover secretos a **Key Vault**, TLS/SSL, y usuarios/roles m√≠nimos.

---

## 9) Operaci√≥n (c√≥mo correr la demo)

1) **Provisionar**: `Step00 - Terraform CI/CD` (o `terraform apply`).
2) **Arrancar servicios**: `step10-start-services.yml` (o `02-restart-lab-services.yml`).
3) **Sembrar datos / DL**: `04-init-data-plane.yml` y `05-install-ml-deps.yml`.
4) **Metabase**: `06-setup-metabase.yml` (local) o `step11-setup-metabase-public.yml` (p√∫blico controlado).
5) **E2E**: `step12-bringup-demo-e2e.yml` para correr todo y validar con `step13-sanity-checks.yml`.

---

## 10) Visualizaciones base (Metabase)

- **Total mensajes** ‚Äì KPI (count).
- **Conteo por sentimiento** ‚Äì barras.
- **Mensajes por d√≠a** ‚Äì l√≠nea (agregaci√≥n por d√≠a sobre `ingest_ts`).

Las 3 tarjetas se agregan al tablero **`Sentiment_Streaming_Kafka_Mongo_DL_MySQL`**.

---

## 11) Directorio del repo (resumen pr√°ctico)

- **`.github/workflows/`** ‚Äì automatizaci√≥n y orquestaci√≥n.
- **`scripts/`** ‚Äì _bootstrap_, productores/consumidores y workers.
- **`notebook/`** ‚Äì cuadernos de exploraci√≥n y pruebas.
- **`docs/`** ‚Äì gu√≠as, arquitectura y evidencias.
- **`terraform/`** ‚Äì IaC Azure.

---

## 12) Extensiones y variantes

- Sustituir **MySQL** por **PostgreSQL** o **Databricks** manteniendo Metabase.
- A√±adir **Airflow** para orquestaci√≥n programada.
- Sustituir el worker DL por un **serving** en contenedor (FastAPI/Triton) y llamar v√≠a REST.

---

### üß≠ En una frase
**Kafka ‚Üí Mongo (crudo) ‚Üí DL (clasifica) ‚Üí MySQL (DW) ‚Üí Metabase (BI)**, todo reproducible desde GitHub Actions y Docker en una VM de Azure.

